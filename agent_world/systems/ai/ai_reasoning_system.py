"""Basic LLM reasoning loop for AI-controlled agents."""

from __future__ import annotations

from typing import Any, List, Optional, Tuple
import re # For checking hex string pattern

COOLDOWN_TICKS = 10 # How many ticks an agent waits after an LLM action before requesting another

from ...core.components.ai_state import AIState
from ...ai.llm.prompt_builder import build_prompt
from ...ai.llm.llm_manager import LLMManager
from .behavior_tree import BehaviorTree, build_fallback_tree

# Define strings that are considered non-actions or failures from the LLM
NON_ACTION_STRINGS = [
    "<wait>",
    "<error_llm_call>",
    "<wait_llm_not_ready>",
    "<error_llm_setup>",
    "<error_llm_loop_missing>",
    "<error_llm_queue_full>",
    "<error_llm_no_choices>",
    "<error_llm_malformed_choice>",
    "<error_llm_malformed_message>",
    "<error_llm_malformed_content>",
    "<error_llm_request>",
    "<error_llm_parsing>",
    "<llm_empty_response>", # For when LLM returns an empty string
    "" # Explicitly include empty string
]
# Add HTTP error variations
for i in range(400, 600):
    NON_ACTION_STRINGS.append(f"<error_llm_http_{i}>")

# Precompile a regex for typical prompt_id (UUID hex string)
# Prompt IDs are generated by uuid.uuid4().hex, which are 32 lowercase hex characters
PROMPT_ID_PATTERN = re.compile(r"^[a-f0-9]{32}$")


class AIReasoningSystem:
    """Query the LLM for each agent and queue resulting actions."""

    def __init__(
        self,
        world: Any,
        llm: LLMManager,
        action_tuples_list: List[Tuple[int, str]], # This is world.raw_actions_with_actor
        behavior_tree: Optional[BehaviorTree] = None,
    ) -> None:
        self.world = world
        self.llm = llm
        self.action_tuples_list = action_tuples_list
        self.behavior_tree = behavior_tree or build_fallback_tree()

    def update(self, tick: int) -> None: # tick parameter is passed by SystemsManager
        """Handle pending and new LLM prompts for all agents."""

        if not all([
            self.world.entity_manager, 
            self.world.component_manager, 
            self.world.time_manager,
            self.world.llm_manager_instance, 
            hasattr(self.world, 'async_llm_responses')
        ]):
            # print(f"[Tick {tick}][AIReasoningSystem] World or essential managers not ready.")
            return

        em = self.world.entity_manager
        cm = self.world.component_manager
        tm = self.world.time_manager
        
        for entity_id in list(em.all_entities.keys()):
            ai_comp = cm.get_component(entity_id, AIState)
            if ai_comp is None:
                continue

            if tm.tick_counter <= ai_comp.last_llm_action_tick + COOLDOWN_TICKS and ai_comp.last_llm_action_tick != -1:
                continue 

            final_action_to_take: str | None = None
            llm_attempt_made_or_resolved = False # Track if we interacted with LLM this tick

            if ai_comp.pending_llm_prompt_id is None:
                # No pending request, try to make a new one
                if self.llm.mode == "live":
                    llm_attempt_made_or_resolved = True
                    prompt = build_prompt(entity_id, self.world)
                    returned_value = self.llm.request(prompt, self.world)

                    if returned_value in NON_ACTION_STRINGS:
                        print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] LLM returned immediate non-action/error: '{returned_value}' for prompt: {prompt[:70]}...")
                        # final_action_to_take remains None, BT will be tried.
                    elif PROMPT_ID_PATTERN.match(returned_value):
                        # This is a new prompt_id because llm.request scheduled a new call
                        ai_comp.pending_llm_prompt_id = returned_value
                        print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] New LLM request initiated. Prompt ID: {ai_comp.pending_llm_prompt_id}. Prompt: {prompt[:70]}...")
                    else:
                        # This is an immediate valid action (e.g., from cache, or echo mode if not live)
                        print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] LLM returned immediate valid action: '{returned_value}' (e.g. cached/echo) for prompt: {prompt[:70]}...")
                        final_action_to_take = returned_value
                
                elif self.llm.mode == "echo": # Handle echo mode separately if not covered by "live"
                    llm_attempt_made_or_resolved = True
                    prompt = build_prompt(entity_id, self.world) 
                    returned_action = self.llm.request(prompt, self.world) # LLMManager handles echo logic
                    print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] LLM Echo mode response: '{returned_action}' for prompt: {prompt[:70]}...")
                    if returned_action not in NON_ACTION_STRINGS:
                        final_action_to_take = returned_action
                # If LLM mode is "offline", llm.request returns "<wait>", which is in NON_ACTION_STRINGS,
                # so it will fall through to behavior tree. No specific handling needed here.

            else: # Has a pending LLM request
                llm_attempt_made_or_resolved = True
                future = self.world.async_llm_responses.get(ai_comp.pending_llm_prompt_id)
                if future and future.done():
                    try:
                        action_from_llm = future.result()
                        print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] LLM Future resolved. Prompt ID {ai_comp.pending_llm_prompt_id}. Result: '{action_from_llm}'")
                        if action_from_llm not in NON_ACTION_STRINGS:
                            final_action_to_take = action_from_llm
                    except Exception as e:
                        print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] Error getting result from LLM future for Prompt ID {ai_comp.pending_llm_prompt_id}: {e}")
                    
                    self.world.async_llm_responses.pop(ai_comp.pending_llm_prompt_id, None)
                    ai_comp.pending_llm_prompt_id = None
                # else: Future not done yet, agent waits for next AIReasoningSystem update.

            # If no action from LLM, try behavior tree
            if not final_action_to_take and self.behavior_tree:
                # Only log BT usage if an LLM attempt was made/resolved OR if LLM is offline
                if llm_attempt_made_or_resolved or self.llm.mode == "offline":
                    print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] No valid LLM action. Mode: {self.llm.mode}. Trying behavior tree.")
                
                fallback_action = self.behavior_tree.run(entity_id, self.world)
                if fallback_action:
                    final_action_to_take = fallback_action
                    # print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] Behavior tree provided fallback: '{fallback_action}'")
            
            if final_action_to_take:
                print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] Decided action: '{final_action_to_take}' (LLM Mode: {self.llm.mode}, Source: {'LLM' if llm_attempt_made_or_resolved and final_action_to_take not in self.behavior_tree.run(entity_id,self.world) else 'BT'})") # Indicate source
                self.action_tuples_list.append((entity_id, final_action_to_take))
                ai_comp.last_llm_action_tick = tm.tick_counter
            elif llm_attempt_made_or_resolved and ai_comp.pending_llm_prompt_id is None: 
                # If an LLM attempt was made/resolved, but resulted in NO action (e.g. LLM error, or LLM returned <wait>),
                # and NO BT action was taken (e.g. BT also returned None, or no BT),
                # still update last_llm_action_tick to enforce cooldown and prevent spamming failed LLM calls.
                # This happens if the future resolved to a NON_ACTION_STRING, or immediate request was NON_ACTION_STRING
                # and behavior tree also didn't yield an action.
                # Or, if the goal is for it to retry LLM immediately on <wait> type errors, then this line should be conditional.
                # Current behavior: cooldown even on failed LLM attempt cycle if BT also fails.
                # print(f"[Tick {tm.tick_counter}][AI Agent {entity_id}] LLM attempt cycle completed with no action, pending_id cleared. Cooldown started.") # DEBUG
                ai_comp.last_llm_action_tick = tm.tick_counter


__all__ = ["AIReasoningSystem"]