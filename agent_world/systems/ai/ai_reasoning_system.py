"""Basic LLM reasoning loop for AI-controlled agents."""

from __future__ import annotations

from typing import Any, List, Optional, Tuple
import re  # For checking hex string pattern
import logging

logger = logging.getLogger(__name__)

COOLDOWN_TICKS = 10 # How many ticks an agent waits after an LLM action before requesting another

from ...core.components.ai_state import AIState
from ...ai.llm.prompt_builder import build_prompt
from ...ai.llm.llm_manager import LLMManager
from ...core.components.role import RoleComponent
from ...ai.planning.llm_planner import LLMPlanner
from ...core.components.position import Position
from ...systems.movement import pathfinding
from .behavior_tree import BehaviorTree, build_fallback_tree
from .actions import parse_action_string, ActionQueue

# Define strings that are considered non-actions or failures from the LLM
NON_ACTION_STRINGS = [
    "<wait>",
    "<error_llm_call>",
    "<wait_llm_not_ready>",
    "<error_llm_setup>",
    "<error_llm_loop_missing>",
    "<error_llm_queue_full>",
    "<error_llm_no_choices>",
    "<error_llm_malformed_choice>",
    "<error_llm_malformed_message>",
    "<error_llm_malformed_content>",
    "<error_llm_request>",
    "<error_llm_parsing>",
    "<llm_empty_response>", # For when LLM returns an empty string
    "" # Explicitly include empty string
]
# Add HTTP error variations
for i in range(400, 600):
    NON_ACTION_STRINGS.append(f"<error_llm_http_{i}>")

# Precompile a regex for typical prompt_id (UUID hex string)
# Prompt IDs are generated by uuid.uuid4().hex, which are 32 lowercase hex characters
PROMPT_ID_PATTERN = re.compile(r"^[a-f0-9]{32}$")


class AIReasoningSystem:
    """Query the LLM for each agent and queue resulting actions."""

    def __init__(
        self,
        world: Any,
        llm: LLMManager,
        action_tuples_list: List[Tuple[int, str]], # This is world.raw_actions_with_actor
        behavior_tree: Optional[BehaviorTree] = None,
        planner: LLMPlanner | None = None,
    ) -> None:
        self.world = world
        self.llm = llm
        self.action_tuples_list = action_tuples_list
        self.behavior_tree = behavior_tree or build_fallback_tree()
        self.planner = planner or LLMPlanner(llm)
        self.action_queue: ActionQueue | None = getattr(world, "action_queue", None)
        self._sink_wrapped = isinstance(action_tuples_list, RawActionCollector)

    @staticmethod
    def _first_obstacle_in_direct_path(start: Tuple[int, int], goal: Tuple[int, int]) -> Tuple[int, int] | None:
        """Return the first blocking obstacle when moving directly from start to goal."""
        x, y = start
        gx, gy = goal
        while x != gx:
            x += 1 if gx > x else -1
            if pathfinding.is_blocked((x, y)):
                return (x, y)
        while y != gy:
            y += 1 if gy > y else -1
            if pathfinding.is_blocked((x, y)):
                return (x, y)
        return None

    def _contextualize_generate_ability(self, action_text: str, ai_comp: AIState, entity_id: int) -> str:
        """Ensure GENERATE_ABILITY descriptions mention relevant obstacle context."""
        if not action_text.upper().startswith("GENERATE_ABILITY"):
            return action_text

        parts = action_text.split(maxsplit=1)
        if len(parts) < 2:
            return action_text # Should not happen if action_verb is GENERATE_ABILITY

        desc = parts[1] # This will be the description part
        
        # Check if description already contains coordinates like (X,Y)
        if re.search(r"\(\s*\d+\s*,\s*\d+\s*\)", desc):
            return action_text  # Already contextualized with coords

        cm = self.world.component_manager
        obs_coords: Tuple[int, int] | None = None
        goal_target_display: Any = None # For logging/description

        # Try to get context from the current plan step if it's about an obstacle
        if ai_comp.current_plan: # This check might be redundant if called after popping, but good for safety
            # This logic assumes the current step *being processed* is the one related to GENERATE_ABILITY.
            # If GENERATE_ABILITY is a *result* of a DEAL_WITH_OBSTACLE step,
            # then the current_plan might be empty or on the next step.
            # This function might need to look at the *previously processed* step,
            # or have the obstacle context passed to it.
            # For now, let's assume the LLM prompt for GENERATE_ABILITY was formed
            # when DEAL_WITH_OBSTACLE was the active step.

            # Simplified: If the LLM decides to GENERATE_ABILITY, it should have gotten context
            # from the prompt. We look for general path blockage if no specific plan step context.
            pass # Placeholder for more specific plan step context if available

        # If no specific plan context, check general path to current goal
        if obs_coords is None:
            agent_pos = cm.get_component(entity_id, Position)
            if ai_comp.goals and agent_pos:
                goal = ai_comp.goals[0]
                target_entity_id_or_coords = getattr(goal, "target", None)
                goal_target_display = target_entity_id_or_coords

                target_coords_tuple: Tuple[int, int] | None = None
                if isinstance(target_entity_id_or_coords, int):
                    t_pos = cm.get_component(target_entity_id_or_coords, Position)
                    if t_pos: target_coords_tuple = (t_pos.x, t_pos.y)
                elif isinstance(target_entity_id_or_coords, (tuple, list)) and len(target_entity_id_or_coords) == 2:
                    try: target_coords_tuple = (int(target_entity_id_or_coords[0]), int(target_entity_id_or_coords[1]))
                    except ValueError: pass
                
                if target_coords_tuple:
                    obs_coords = self._first_obstacle_in_direct_path(
                        (agent_pos.x, agent_pos.y), target_coords_tuple
                    )

        if obs_coords is not None:
            obs_str = f"({obs_coords[0]},{obs_coords[1]})"
            if obs_str not in desc: # Only add if not already mentioned
                if goal_target_display:
                    new_desc = f"{desc} for obstacle at {obs_str} blocking path to goal target {goal_target_display}"
                else:
                    new_desc = f"{desc} for obstacle at {obs_str}"
                logger.info(
                    "[AIReasoningSystem] Contextualized GENERATE_ABILITY for agent %s: '%s' -> '%s'",
                    entity_id, action_text, f"GENERATE_ABILITY {new_desc}"
                )
                return f"GENERATE_ABILITY {new_desc}"
        
        return action_text

    def _convert_plan_step_to_action(self, step, entity_id: int) -> Optional[str]:
        """Try to convert a plan step directly to an action without LLM."""
        if step.action.upper() == "MOVE_TO":
            # For MOVE_TO, we need to compute the first move direction
            cm = self.world.component_manager
            agent_pos = cm.get_component(entity_id, Position)
            if not agent_pos:
                return None
                
            target_coords = None
            if isinstance(step.target, int):
                # Target is an entity ID
                target_pos = cm.get_component(step.target, Position)
                if target_pos:
                    target_coords = (target_pos.x, target_pos.y)
            elif step.parameters.get("target_coords"):
                target_coords = step.parameters["target_coords"]
            elif isinstance(step.target, (tuple, list)) and len(step.target) == 2:
                target_coords = (int(step.target[0]), int(step.target[1]))
                
            if target_coords:
                # Simple greedy pathfinding - move towards target
                dx = target_coords[0] - agent_pos.x
                dy = target_coords[1] - agent_pos.y
                
                # Prefer larger difference
                if abs(dx) > abs(dy):
                    if dx > 0:
                        return "MOVE E"
                    else:
                        return "MOVE W"
                elif dy != 0:
                    if dy > 0:
                        return "MOVE S"
                    else:
                        return "MOVE N"
                else:
                    # Already at target
                    return None
        
        # For other direct actions, construct from the step
        elif step.action.upper() in {"MOVE", "IDLE", "PICKUP", "ATTACK", "USE_ABILITY"}:
            action_parts = [step.action.upper()]
            if step.target is not None:
                action_parts.append(str(step.target))
            elif step.parameters.get("arg"):
                action_parts.append(str(step.parameters["arg"]))
            return " ".join(action_parts)
            
        return None


    def update(self, tick: int) -> None: # tick parameter is passed by SystemsManager
        """Handle pending and new LLM prompts for all agents."""

        if not all([
            self.world.entity_manager, 
            self.world.component_manager, 
            self.world.time_manager,
            self.world.llm_manager_instance, 
            hasattr(self.world, 'async_llm_responses')
        ]):
            return

        em = self.world.entity_manager
        cm = self.world.component_manager
        tm = self.world.time_manager
        
        for entity_id in list(em.all_entities.keys()):
            ai_comp = cm.get_component(entity_id, AIState)
            if ai_comp is None:
                continue

            # --- Retry logic for failed plan steps (moved up) ---
            # This flag is set by MovementSystem if a BT move (or any move) was blocked.
            # Or if an action execution system reports a failure for a plan step.
            if ai_comp.last_bt_move_failed or (ai_comp.last_error and ai_comp.current_plan):
                logger.debug(
                    "[Tick %s][AI Agent %s] Plan step failed or BT move failed. Incrementing retries. Current plan: %s",
                    tm.tick_counter, entity_id, ai_comp.current_plan[0] if ai_comp.current_plan else "None"
                )
                ai_comp.plan_step_retries += 1
                ai_comp.last_bt_move_failed = False # Reset flag
                ai_comp.last_error = None # Reset flag

            if ai_comp.plan_step_retries > ai_comp.max_plan_step_retries:
                logger.warning(
                    "[Tick %s][AI Agent %s] Max plan step retries (%s) exceeded for step. Clearing plan.",
                    tm.tick_counter, entity_id, ai_comp.max_plan_step_retries
                )
                ai_comp.current_plan.clear()
                ai_comp.plan_step_retries = 0
                ai_comp.pending_llm_prompt_id = None # Clear any pending LLM for the failed plan
                ai_comp.last_plan_generation_tick = tm.tick_counter # Prevent immediate replan this tick
                continue # Move to next agent, will replan next reasoning cycle

            # --- Role-based LLM usage ---
            role_comp = cm.get_component(entity_id, RoleComponent)
            if role_comp and not role_comp.uses_llm:
                if self.behavior_tree:
                    action = self.behavior_tree.run(entity_id, self.world)
                    if action:
                        if not self._sink_wrapped: # Assuming direct enqueue if not wrapped
                            if self.action_queue is None:
                                self.action_queue = getattr(self.world, "action_queue", None)
                            if self.action_queue is not None:
                                for act_obj in parse_action_string(entity_id, action):
                                    self.action_queue._queue.append(act_obj) # Enqueue Action objects
                        else: # If wrapped, append raw string
                            self.action_tuples_list.append((entity_id, action))
                continue # Done with this non-LLM agent

            # --- Plan Generation ---
            if (
                ai_comp.goals
                and not ai_comp.current_plan # No current plan
                and ai_comp.last_plan_generation_tick != tm.tick_counter # And we didn't try to plan this very tick
                and ai_comp.pending_llm_prompt_id is None # And not waiting for a decision LLM
            ):
                logger.debug(
                    "[Tick %s][AI Agent %s] Has goals, no plan, and not waiting for LLM. Requesting new plan.",
                    tm.tick_counter, entity_id
                )
                ai_comp.current_plan = self.planner.create_plan(
                    entity_id, ai_comp.goals, self.world
                )
                ai_comp.last_plan_generation_tick = tm.tick_counter
                if ai_comp.current_plan:
                    logger.info(
                        "[Tick %s][AI Agent %s] Planner generated new plan: %s",
                        tm.tick_counter, entity_id, ai_comp.current_plan
                    )
                else:
                    logger.warning(
                        "[Tick %s][AI Agent %s] Planner failed to generate a plan.",
                        tm.tick_counter, entity_id
                    )
            
            # --- Cooldown and Rethink Logic ---
            bypass_cooldown = False
            if ai_comp.needs_immediate_rethink:
                logger.debug("[Tick %s][AI Agent %s] Needs immediate rethink.", tm.tick_counter, entity_id)
                ai_comp.needs_immediate_rethink = False
                bypass_cooldown = True

            if (
                not bypass_cooldown
                and tm.tick_counter <= ai_comp.last_llm_action_tick + COOLDOWN_TICKS
                and ai_comp.last_llm_action_tick != -1 # Ensure not first tick
            ):
                continue # Agent is on cooldown

            # --- Action Decision/Execution ---
            final_action_to_take: str | None = None
            llm_attempt_made_or_resolved_this_cycle = False 
            
            plan_step_processed_this_cycle = False
            current_plan_step = None
            waiting_for_plan_step_llm = False

            if ai_comp.current_plan:
                current_plan_step = ai_comp.current_plan[0] # Look at the current step
                step_type_upper = (current_plan_step.step_type.upper() if current_plan_step.step_type else current_plan_step.action.upper())
                
                logger.debug("[Tick %s][AI Agent %s] Processing plan step: %s", tm.tick_counter, entity_id, current_plan_step)

                # First, try to convert the plan step directly to an action
                direct_action = self._convert_plan_step_to_action(current_plan_step, entity_id)
                
                if direct_action:
                    final_action_to_take = direct_action
                    logger.info(
                        "[Tick %s][AI Agent %s] Directly executing plan step: '%s' -> '%s'",
                        tm.tick_counter, entity_id, current_plan_step, final_action_to_take
                    )
                    # Successfully initiated a plan step. Pop it and reset retries.
                    ai_comp.current_plan.pop(0)
                    ai_comp.plan_step_retries = 0
                    plan_step_processed_this_cycle = True
                
                # Special plan steps that guide LLM prompting
                elif step_type_upper in {"DEAL_WITH_OBSTACLE", "GENERATE_ABILITY_FOR_OBSTACLE"}:
                    waiting_for_plan_step_llm = True
                    obstacle_context = ""
                    if step_type_upper == "DEAL_WITH_OBSTACLE":
                        coords = current_plan_step.parameters.get("coords_str") or current_plan_step.parameters.get("coords") or current_plan_step.parameters.get("obstacle_ref")
                        obstacle_context = f"Obstacle at {coords} blocks your path. How do you proceed? Consider using/generating an ability."
                    elif step_type_upper == "GENERATE_ABILITY_FOR_OBSTACLE":
                        desc = current_plan_step.parameters.get("description", "deal with an obstacle")
                        obstacle_context = f"You need to generate an ability to '{desc}'. Formulate the GENERATE_ABILITY action."
                    
                    # This step requires LLM deliberation.
                    # The prompt will be built using this context.
                    # The plan step will be popped *after* LLM returns a valid action for it.
                    # Fall through to LLM request logic below.
                    # The obstacle_context will be appended to the standard prompt.
                    logger.debug(
                         "[Tick %s][AI Agent %s] Plan step '%s' requires LLM. Context: %s",
                         tm.tick_counter, entity_id, step_type_upper, obstacle_context
                    )
                    # No final_action_to_take yet, let LLM decide.
                    # We set a flag or pass context to the LLM prompter.
                    # The `plan_hint` mechanism in prompt builder might be used or `obstacle_prompt`
                    plan_step_processed_this_cycle = True # Mark as initiated for popping later IF LLM succeeds for this step

                else: # Other plan steps that we can't directly convert need LLM
                    waiting_for_plan_step_llm = True
                    logger.debug(
                        "[Tick %s][AI Agent %s] Plan step '%s' requires LLM deliberation.",
                        tm.tick_counter, entity_id, step_type_upper
                    )
                    # Fall through to LLM request logic.
                    plan_step_processed_this_cycle = True # Mark as initiated for popping later IF LLM succeeds for this step


            # --- LLM Interaction (if no direct action from plan or if plan step needs LLM) ---
            if final_action_to_take is None and waiting_for_plan_step_llm:
                if ai_comp.pending_llm_prompt_id is None: # No pending LLM request
                    if self.llm.mode == "live" or self.llm.mode == "echo":
                        llm_attempt_made_or_resolved_this_cycle = True
                        
                        # Build prompt, potentially adding plan step context
                        prompt_context_for_llm = ""
                        if ai_comp.current_plan and plan_step_processed_this_cycle: # If we are processing a plan step that needs LLM
                            step = ai_comp.current_plan[0]
                            step_type_upper = (step.step_type.upper() if step.step_type else step.action.upper())
                            if step_type_upper == "DEAL_WITH_OBSTACLE":
                                coords = step.parameters.get("coords_str") or step.parameters.get("coords") or step.parameters.get("obstacle_ref")
                                prompt_context_for_llm = f"\nSYSTEM TASK: Obstacle at {coords} blocks your path. Decide how to proceed. Consider using/generating an ability."
                            elif step_type_upper == "GENERATE_ABILITY_FOR_OBSTACLE":
                                desc = step.parameters.get("description", "deal with an obstacle")
                                prompt_context_for_llm = f"\nSYSTEM TASK: You need to generate an ability to '{desc}'. Formulate the GENERATE_ABILITY action string."
                            else: # Generic plan step for LLM
                                prompt_context_for_llm = f"\nSYSTEM TASK: Current plan step: {step.action}"
                                if step.target: prompt_context_for_llm += f" {step.target}"
                                if step.parameters: prompt_context_for_llm += f" with params {step.parameters}"
                                prompt_context_for_llm += ". Decide your specific action."
                        
                        prompt = build_prompt(entity_id, self.world) + prompt_context_for_llm

                        # Role-based ability generation restriction
                        if role_comp and not role_comp.can_request_abilities:
                            prompt = "\n".join(line for line in prompt.splitlines() if "GENERATE_ABILITY" not in line.upper())
                        
                        returned_value = self.llm.request(prompt, self.world)

                        if returned_value in NON_ACTION_STRINGS:
                            logger.debug(
                                "[Tick %s][AI Agent %s] LLM immediate non-action: '%s'. Prompt: %s...",
                                tm.tick_counter, entity_id, returned_value, prompt[:70]
                            )
                        elif PROMPT_ID_PATTERN.match(returned_value):
                            ai_comp.pending_llm_prompt_id = returned_value
                            logger.debug(
                                "[Tick %s][AI Agent %s] New LLM request. Prompt ID: %s. Prompt: %s...",
                                tm.tick_counter, entity_id, ai_comp.pending_llm_prompt_id, prompt[:70]
                            )
                        else: # Immediate valid action
                            final_action_to_take = returned_value
                            logger.info(
                                "[Tick %s][AI Agent %s] LLM immediate valid action: '%s'. Prompt: %s...",
                                tm.tick_counter, entity_id, final_action_to_take, prompt[:70]
                            )
                            # If this action was for a plan step, consume the plan step
                            if ai_comp.current_plan and plan_step_processed_this_cycle:
                                logger.debug(
                                    "[Tick %s][AI Agent %s] Consuming plan step %s after immediate LLM action.",
                                    tm.tick_counter, entity_id, ai_comp.current_plan[0]
                                )
                                ai_comp.current_plan.pop(0)
                                ai_comp.plan_step_retries = 0
                            elif not ai_comp.current_plan and plan_step_processed_this_cycle:
                                # This case implies a plan step was marked for processing, but the plan became empty.
                                # This shouldn't happen if logic is correct, but log if it does.
                                logger.warning("[Tick %s][AI Agent %s] plan_step_processed_this_cycle is true, but current_plan is empty after immediate LLM action.",
                                               tm.tick_counter, entity_id)


                elif self.llm.mode == "offline": # Will fall through to BT
                    llm_attempt_made_or_resolved_this_cycle = True # Considered an attempt

            elif ai_comp.pending_llm_prompt_id is not None: # Has a pending LLM request
                llm_attempt_made_or_resolved_this_cycle = True
                future = self.world.async_llm_responses.get(ai_comp.pending_llm_prompt_id)
                if future and future.done():
                    try:
                        action_from_llm = future.result()
                        logger.debug(
                            "[Tick %s][AI Agent %s] LLM Future resolved. ID %s. Result: '%s'",
                            tm.tick_counter, entity_id, ai_comp.pending_llm_prompt_id, action_from_llm
                        )
                        if action_from_llm not in NON_ACTION_STRINGS:
                            final_action_to_take = action_from_llm
                            # If this action was for a plan step, consume the plan step
                            if ai_comp.current_plan and plan_step_processed_this_cycle:
                                logger.debug(
                                    "[Tick %s][AI Agent %s] Consuming plan step %s after resolved LLM future.",
                                    tm.tick_counter, entity_id, ai_comp.current_plan[0]
                                )
                                ai_comp.current_plan.pop(0)
                                ai_comp.plan_step_retries = 0
                            elif not ai_comp.current_plan and plan_step_processed_this_cycle:
                                logger.warning("[Tick %s][AI Agent %s] plan_step_processed_this_cycle is true, but current_plan is empty after LLM future resolution.",
                                               tm.tick_counter, entity_id)

                        # If LLM returned a non-action (error, wait), and it was for a plan step, increment retry
                        elif ai_comp.current_plan and plan_step_processed_this_cycle:
                            logger.warning(
                                "[Tick %s][AI Agent %s] LLM future for plan step resolved to non-action '%s'. Incrementing retries for step %s.",
                                tm.tick_counter, entity_id, action_from_llm, ai_comp.current_plan[0]
                            )
                            ai_comp.plan_step_retries += 1 # This will be checked at the start of next cycle for this agent

                    except Exception as e:
                        logger.warning(
                            "[Tick %s][AI Agent %s] Error from LLM future ID %s: %s. Incrementing retries if for plan step.",
                            tm.tick_counter, entity_id, ai_comp.pending_llm_prompt_id, e
                        )
                        if ai_comp.current_plan and plan_step_processed_this_cycle:
                             ai_comp.plan_step_retries += 1
                    
                    self.world.async_llm_responses.pop(ai_comp.pending_llm_prompt_id, None)
                    ai_comp.pending_llm_prompt_id = None
            
            # --- Behavior Tree Fallback ---
            # CRITICAL FIX: Only use BT if we don't have an active plan that's waiting for LLM
            should_use_bt_fallback = (
                not final_action_to_take 
                and self.behavior_tree
                and (
                    # No plan at all
                    not ai_comp.current_plan
                    # OR we have a plan but NOT waiting for LLM on current step
                    or (ai_comp.current_plan and not waiting_for_plan_step_llm)
                    # OR we're in offline mode
                    or self.llm.mode == "offline"
                )
            )
            
            if should_use_bt_fallback:
                logger.debug(
                    "[Tick %s][AI Agent %s] Using BT fallback (no plan or not waiting for plan LLM)",
                    tm.tick_counter, entity_id
                )
                
                fallback_action = self.behavior_tree.run(entity_id, self.world)
                if fallback_action:
                    final_action_to_take = fallback_action
                    # If BT provides an action, and we were trying to process a plan step via LLM which failed,
                    # this BT action might not satisfy the plan step. The retry logic at the top should handle this.
                    # For now, we don't pop the plan step if BT provides the action,
                    # unless the BT action is considered a successful resolution of the plan step.
                    # This is complex. Simplest: let retry logic handle it if plan is not advanced.
            
            # --- Enqueue Final Action ---
            if final_action_to_take:
                if final_action_to_take.upper().startswith("GENERATE_ABILITY"):
                    final_action_to_take = self._contextualize_generate_ability(
                        final_action_to_take, ai_comp, entity_id
                    )

                logger.info(
                    "[Tick %s][AI Agent %s] Decided action: '%s' (LLM Mode: %s)",
                    tm.tick_counter, entity_id, final_action_to_take.replace("\n", "//"), self.llm.mode
                )

                # Enqueue parsed Action objects
                if self.action_queue is None: # One-time fetch if None
                    self.action_queue = getattr(self.world, "action_queue", None)

                if self.action_queue is not None:
                    parsed_actions_list = parse_action_string(entity_id, final_action_to_take)
                    for act_obj in parsed_actions_list:
                        self.action_queue._queue.append(act_obj)
                else: # Fallback to raw string list if queue is somehow still None (should not happen)
                    self.action_tuples_list.append((entity_id, final_action_to_take))

                ai_comp.last_llm_action_tick = tm.tick_counter # Update cooldown tick
            
            elif llm_attempt_made_or_resolved_this_cycle and ai_comp.pending_llm_prompt_id is None:
                # LLM cycle completed (either immediate or future resolved) but resulted in NO action.
                # And BT also didn't provide an action.
                # This means the agent effectively idles this turn regarding LLM.
                # Still update cooldown to prevent spamming if LLM keeps returning errors.
                logger.debug(
                    "[Tick %s][AI Agent %s] LLM cycle completed with no action and no BT action. Idling. Cooldown applies.",
                    tm.tick_counter, entity_id
                )
                ai_comp.last_llm_action_tick = tm.tick_counter
                if ai_comp.current_plan and plan_step_processed_this_cycle:
                    # If we were trying to process a plan step and it resulted in no action,
                    # count it as a retry for that step.
                    logger.debug(
                        "[Tick %s][AI Agent %s] Plan step %s resulted in no LLM/BT action. Incrementing retries.",
                        tm.tick_counter, entity_id, ai_comp.current_plan[0]
                    )
                    ai_comp.plan_step_retries += 1


__all__ = ["AIReasoningSystem", "RawActionCollector"]


class RawActionCollector(list[tuple[int, str]]):
    """List-like collector that also enqueues parsed actions."""

    def __init__(self, action_queue: ActionQueue) -> None:
        super().__init__()
        self.action_queue = action_queue

    def append(self, item: tuple[int, str]) -> None:  # type: ignore[override]
        # This append is typically called by BehaviorTreeSystem for non-LLM agents
        # or by AIReasoningSystem's fallback if self._sink_wrapped is true.
        # AIReasoningSystem should now directly enqueue to world.action_queue for LLM agents.
        actor_id, text = item
        if self.action_queue is not None: # Ensure queue exists
            parsed = parse_action_string(actor_id, text)
            for act in parsed:
                self.action_queue._queue.append(act) # Enqueue Action objects
        super().append(item) # Keep appending raw string for logging/compatibility if needed